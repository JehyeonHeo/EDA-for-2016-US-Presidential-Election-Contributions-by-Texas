Exploration of Financial Contributions to Presidential Campaigns in Texas by Jehyeon Heo.
========================================================

> **Tip**: You will see quoted sections like this throughout the template to
help you construct your report. Make sure that you remove these notes before
you finish and submit your project!

> **Tip**: One of the requirements of this project is that your code follows
good formatting techniques, including limiting your lines to 80 characters or
less. If you're using RStudio, go into Preferences \> Code \> Display to set up
a margin line to help you keep track of this guideline!

```{r echo=FALSE, message=FALSE, warning=FALSE, Packages}
# Load all of the packages that you end up using in your analysis in this code
# chunk.

# Notice that the parameter "echo" was set to FALSE for this code chunk. This
# prevents the code from displaying in the knitted HTML output. You should set
# echo=FALSE for all code chunks in your file, unless it makes sense for your
# report to show the code that generated a particular plot.

# The other parameters for "message" and "warning" should also be set to FALSE
# for other code chunks once you have verified that each plot comes out as you
# want it to. This will clean up the flow of your report.

library(ggplot2)
library(gridExtra)
library(dplyr)
library(RColorBrewer)
library(GGally)
library(scales)
library(memisc)
library(reshape2)
```

 Now I'm going to load the financial contributions by Texas data and candidates data.

```{r echo=FALSE, Load_the_datas}

# Load the financial data.
Data <- read.csv('ctrbsTX.csv',
                  row.names = NULL,
                  header = TRUE)

# Get header names without 'row.names'.
data_headers <- colnames(Data)[-1]

# In the data, remove the last column which is all NAs.
Data <- Data[,-19]

# Give the data right header names for each columns.
colnames(Data) <- data_headers

# Load the candidates data.
Cand <- read.csv('candidates.csv')

```

> **Tip**: Before you create any plots, it is a good idea to provide a short
introduction into the dataset that you are planning to explore. Replace this
quoted text with that general information!

 In 2016, there was presidential election in United States. At the result of it, Donald Trump became the 45th president of US. He gave sensational impact to Repulican party and became the nominee of it. His biggest rival was Hillary Clinton, Democratic party nominee. Lots of people forecasted that Hillary Clinton would win. But even if she got more votes than Trump in the election, she lost.
 
 In this document, I'm going to explore about financial contributions in Texas to presidential campaigns of 2016 US election. I chose Texas because I was interested in the state.
 
 I got the financial data from [FEC site](http://classic.fec.gov/disclosurep/pnational.do). And I also used the data about candidates. It has gender, party, height and age information of each candidates. I made the data by searching the internet.
 
 Before I enter into analysis, I'm going to introduce the questions that I got about the data.
 1. How was the distribution of the contributions? 
 2. How did the sum of contributions differ by parties or dates or candidates, etc?
 3. I want to know the results of above questions by comparing Hillary and Trump. And also for Republican party and Democratic party.
 4. Which contributer contributed the maximum amount? And who contributed most often?
 
 I'm sure that I'll get more questions as I explore the datas. I'll show you which questions I get when I explore the data and show the results of the exploration.
 
# Basic Data Exploration Section

> **Tip**: In this section, you should perform some preliminary exploration of
your dataset. Run some summaries of the data and create univariate plots to
understand the structure of the individual variables in your dataset. Don't
forget to add a comment after each plot or closely-related group of plots!
There should be multiple code chunks and text sections; the first one below is
just to help you get started.

 Fisrt, I'm going to explore financial data.
 
```{r echo=FALSE, Basic_Exploration_for_Data}

# Get the number of observations and columns.
dim(Data)

# Show the structure of the data.
str(Data)

# Show the distributions of the data by summary.
summary(Data)

# Get the number of candidates and columns.
print('Number of candidates in Data:')
length(unique(Data$cand_nm))

# Show some contributers' names.
print("Show top 5 most common contributers' names")
summary(Data$contbr_nm)[1:5]
```

 The Data has about 550,000 observations and 18 variables. And there are 25 candidates' information in it.
 
 And I can see from the structure and the summary of the Data that it would be difficult to identify unique contributers. If I try to sort out distinctive contributers by using names, there can be lots of different people with same name. Even if I try to use city or occupation variables too, I cannot know whether the contributions are made by diffrent people who live in the same city or by same person who moved to other city and changed his or her job. 
 
 I'm going to show the example below.
 
```{r echo=FALSE, Same_name_different_people_example}

# Show the states of 'ROBINSON, ROBBIE'.
bonnie <- subset(Data, contbr_nm == 'RUDOLPH, BONNIE')

print("Show the states of 'RUDOLPH, BONNIE'.")

print('How many unique city names are registered for him?')
length(unique(bonnie$contbr_city))

print('What is the city names?')
unique(bonnie$contbr_city)

print('How many unique zip codes are registered for him?')
length(unique(bonnie$contbr_zip))

print('What is the zip codes?')
unique(bonnie$contbr_zip)

print('How many of people are registered as his employer?')
length(unique(bonnie$contbr_employer))

print('Who is his employer?')
unique(bonnie$contbr_employer)

print('How many occupations are registered for him?')
length(unique(bonnie$contbr_occupation))

print('What is his occupation?')
unique(bonnie$contbr_occupation)
```

 For example, in the data, it is written that RUDOLPH, BONNIE contributed 463 times. And it looked like he lives in Laredo, Texas. When I see the city name with zip codes and search about it using google, I think that Laredo is wrongly written to 'Latedo'.
 But when I see the employer and occupation of him, I cannot but have a question about the name's uniqueness. Is he retired? Or is he working at a university? Or did he work at a university and retired? I cannot know about it using only this data.
 Therefore I cannot answer the questions related with 'unique' contributers using this data.
 
 When I see the structure of Data, I found that the type of contb_receipt_dt should be date, not string. I'm going to change the type. And I also think that it is better to make types of file_num and tran_id string, not num or factor because there are too many different cases.
 
```{r echo=FALSE, Change_types}

# Set locale of R.
print("Set locale as 'C'")
Sys.setlocale("LC_TIME", "C")

# Change the type to Date.
Data$contb_receipt_dt <- as.Date(
  Data$contb_receipt_dt, '%d-%b-%y'
)

# Change the types of file_num and tran_id.
Data$file_num <- as.character(Data$file_num)
Data$tran_id <- as.character(Data$tran_id)

# Check the result using str function.
str(Data$contb_receipt_dt)
str(Data$file_num)
str(Data$tran_id)
```

 The type of contb_receipt_dt values are changed to date. And the types of file_num and tran_id values are changed to string.
 
 Now I'm going to explore candidates data, too.

```{r echo=FALSE, Basic_exploration_for_Cand}

# Get the number of observations and columns.
dim(Cand)

# Show the structure of the data.
str(Cand)

# Show the distributions of the data by summary.
summary(Cand)

# Show whether the unique values of the candidates' names are all equal to the cand's X values.
print("If the unique values of the candidates' names in Data are all equal to the values in cand:")

all(unique(Data$cand_nm) == Cand$X)

```

 There are 25 candidates' information in Cand. 17 of them are included in Repulican party and 5 of them are in Democratic party. And only 3 of all candidates are female.

 I think that it is good to add new column which notify who became presidential nominee from each party. I'm going to name the column as 'if_nominee' and assign TRUE for nominees and FALSE for others. And I'm going to regard Evan McMullin, independent presidential candidate as a nominee.

```{r echo=FALSE, Make_if_nominee_column}

nominees = c('Clinton, Hillary Rodham', 
             'Trump, Donald J.',
             'Johnson, Gary',
             'McMullin, Evan',
             'Stein, Jill')

Cand$if_nominee <- ifelse(Cand$cand_nm %in% nominees, TRUE, FALSE)

summary(Cand$if_nominee)
```

 5 candidates became nominees and others couldn't(or didn't).

 When I explored the candidates' data, I found that the values of the candidates' names are same for Data and Cand that I can merge Data and Cand by outer join using 'cand_nm' column. I'm going to use only 'cand_nm', 'cand_party' and 'if_nominee' columns to join.

```{r echo=FALSE, Outer_join_Data_and_Cand}

# Merge the 'Data' and 'Cand' by outer join.
Data <- merge(x = Data, 
              y = Cand[,c('cand_nm', 'cand_party', 'if_nominee')],
              by = 'cand_nm',
              all.x = TRUE)

print('Show the names of the columns after merged')
names(Data)
```

 I can see that 'cand_party' and 'if_nominee' columns are added to Data.

# Univariate Plots Section

 Now I'm going to get univariate plots.
 
 First, I'm going to show the distribution of the count of contributions for each candidates. And I'll also show what is the percentages of total for each count.
 
 I decided to use bar plot because the x variable is names, categorical values and the y variable is counts. I think that I will use bar plot lots of times because most of variables in Data are categorical values.
 
```{r echo=FALSE, Univariate_cand_nm_counts}

#From now on, I'll make some variables to pass through table, sort and as.data.frame function. I do them to draw ggplot graph in order by counts. And I can filter the values by counts easily.

# I designated dnn in table function to give the name to the dimensions in the result. If I don't designate it, the default name is 'Var1'.
# I also designated responseName in as.data.frame function to give the name to the responses in the result. If I don't designate it, the default name is 'Freq'.
# I designated decreasing equal T in sort function to make names with more counts appear at head.
name_counts <- as.data.frame(sort(table(Data$cand_nm, dnn = 'name'),
                                  decreasing = T),
                             responseName = 'count')

name_counts

# I'm going to often use theme function in ggplot. It is for rotating x labels  90 degrees when the label names are long. And I designated hjust = 1 to align the texts to the left of the plot and vjust = 0.5 to align them to each ticks.
ggplot(aes(x = name, y = count),
       data = name_counts) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I chose count/sum(count) as y variable to express percentage.
ggplot(aes(x = name, y = count/sum(count)),
       data = name_counts) +
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = percent_format()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

  Clinton got the most number of contributions. After her, Cruz, Sanders, Trump, Carson, etc. follow. When change the counts to percentages, Clinton got about 38% and Cruz, Sanders, Trump and Carson followed by about 25%, 15%, 14%, 5% each.

 In this time, I'm going to show the distribution of the count of contributions in each cities in Texas.
 
```{r echo=FALSE, Univariate_city_counts}

cities_counts <- as.data.frame(sort(table(Data$contbr_city, dnn = 'name'),
                                    decreasing = T),
                               responseName = 'count')

print("Number of contributers' cities")
length(cities_counts$name)

ggplot(aes(x = name, y = count),
       data = cities_counts[1:10, ]) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 There are 2252 city names in the data that I showed top 10 results.
 
 The top 10 cities of Texas by population ordered by rank are Houston, San Antonio, Dallas, Austin, Fort Worth, El paso, Arlington, Corpus Christi, Plano and Laredo. But when I see the top 10 counts by contributions, the rank is a little different from the rank by population. San Antonio changed the rank with Austin. And while Corpus Christi and Laredo are inclued in populated top 10, they didn't appear at top 10 counts.
 
 In this time, I'm going to show the histogram of contribution amounts in Texas. I can use histogram this time, because I can consider contribution amounts as continuous variable.

```{r echo=FALSE, Univariate_contribution_amount}

summary(Data$contb_receipt_amt)

print('Top 6 most frequent contribution amounts:')
head(sort(table(Data$contb_receipt_amt), decreasing = T))

# I designated binwidth as 100$, because the range of amounts is about $30,000.
ggplot(aes(x = contb_receipt_amt),
       data = Data) +
  geom_histogram(binwidth = 100) +
  scale_x_continuous(breaks = seq(-15000, 15000, 5000))
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Show the histogram for center 50% of amounts. I designated binwidth as 1$, because the range of IQR range is $80.
ggplot(aes(x = contb_receipt_amt),
       data = subset(Data,
                     contb_receipt_amt >= quantile(Data$contb_receipt_amt, 0.25) & contb_receipt_amt <= quantile(Data$contb_receipt_amt, 0.75))) +
  geom_histogram(binwidth = 1) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  scale_x_continuous(limits = c(15, 105))

```
 
 The minimum and maximum amount was -\$16,600 and \$15,000 each. It is weird that there are - values of contributions. I wonder what causes it.
 
 The most common contribution amount is \$25. \$50, \$100 follow it. It is unexpected to see that 25$ is the most common one because I thought that it is convenient to contribute an amount in the tens.
 
 I can see from the table and histogram that most of contributions are in between \$20 and \$100.

 From now on, I'm going to investigate about negative values in contribution amounts.

```{r echo = FALSE, Univariate_more_about_amounts}

minus_amounts <- subset(Data, contb_receipt_amt < 0)

summary(minus_amounts$contb_receipt_amt)

print('Top 6 negative amounts:')
head(sort(minus_amounts$contb_receipt_amt))

print('Datas whose contribution amounts are less than -$10,000:')
subset(minus_amounts, contb_receipt_amt < -10000)

print('Datas about DURHAM, JOE and CLARK, ELLOINE M.')
subset(Data, contbr_nm %in% c('DURHAM, JOE', 'CLARK, ELLOINE M.'))

# Get the descriptions about them to know the causes.
minus_amounts.description <- as.data.frame(sort(
  table(minus_amounts$receipt_desc, dnn = 'description'),
  decreasing = T),
  responseName = 'count'
  )

print('Top 6 descriptions for negative values:')
head(minus_amounts.description)

ggplot(aes(x = description, y = count),
       data = head(minus_amounts.description)) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I also want to know why there are amounts whose values are above $5,400.
more_than_5400_amounts <- subset(Data, contb_receipt_amt > 5400)

# Get the descriptions about them to know the causes.
more_than_5400_amounts.description <-  as.data.frame(sort(
  table(more_than_5400_amounts$receipt_desc, dnn = 'description'),
  decreasing = T),
  responseName = 'count'
  )

print('Show the counts of contribution amounts whose values are above $5,400.')
sort(table(more_than_5400_amounts$contb_receipt_amt),
     decreasing = T)

print('Top 6 descriptions for amounts whose values are above $5,400:')
head(more_than_5400_amounts.description)
```

 I want to know why there are negative values for amounts. First I got the summary of the negative amounts to know the distribution of the values. And I found that the difference of mean and median are more than -\$700. I could guess that it happened because of the existence of outliers like -\$16,600. The result gave me one more question. Why there are outliers of amounts?
 
 And then, I got the top 6 negative amounts to investigate outliers. The 2 most negative amounts were huge compared to the others. Therefore I printed all columns of the values from the data. And I found that they were refunds. How there can be refunds which are more than \$10,000? When I got datas about the contributers from Data, their record were all refunds. 
 
 Therefore I searched their names in FEC site. For 'Durham, Joe' there were some records that aren't in Data. For 'Clark, Elloine M.' there were lots of records but there were some variety of similar names. But I can't find the refund records. I really wonder why they don't exit in there.
 
 Let's come back to the original question. To know why there are negative values, in this time, I got the top 6 most common receipt descriptions and showed using graph, too. The most common reasons were refund, redesignation and reattribution. When I found about them using the internet, there were [contribution limits](https://www.opensecrets.org/overview/limits.php) and [remedying excessive contributions methods](https://www.fec.gov/help-candidates-and-committees/candidate-taking-receipts/remedying-excessive-contribution/). Therefore negative values of contribution amounts aren't wrong datas even though -\$16,600 refund is still weird.
 
 And I got one more question when I saw the contribution limits. an indivisual can contribute maximum \$5,400 for primary and general elections. I want to know why there are some contributions which are more than \$5,400. Therefore I got the counts of them. And I found that most of them are \$10,800. The values weren't dispersed equally. And when I got the counts of receipt descriptions of the contributions, I found that most of them are for reattribution and redesignation. When I saw the result, I guessed that it can be possible that \$10,800 are made for 2 people requesting reattribution. But I cannot know the exact reason using this data.
 
 In this time, I'm going to show the distribution of contribution dates in Texas. I can use line graph this time because I thought that it is the right method to express time series data. I'll show the counts for each day and each month.
 
```{r echo=FALSE, Univariate_contribution_date_counts}

dates_counts <- as.data.frame(table(Data$contb_receipt_dt, dnn = 'date'),
                              responseName = 'count')

# Make the type of date variable in date_counts as Date. I needed to do it because as I made new data.frame, the type of the variable changed to factor.
dates_counts$date <- as.Date(dates_counts$date, format = '%Y-%m-%d')

print('Top 6 most frequent contribution dates:')
head(dates_counts[order(-dates_counts$count),])

ggplot(aes(x = date, y = count),
       data = dates_counts) +
  geom_line() +
  scale_x_date() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# In this time, I needed to designate stat and fun.y in geom_line to aggregate daily data to each month. And I used sum as fun.y to get monthly counts of contributions.
# I made all day parts in date to '01' to aggregate daily counts and get monthly counts. The type of result is character that I used as.Date to change the type to Date.
ggplot(aes(x = as.Date(format(date, '%Y-%m-01'), format = '%Y-%m-%d'), 
           y = count),
       data = dates_counts) +
  geom_line(stat = 'summary',
            fun.y = sum) +
  scale_x_date() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 When I see the top 6 dates of counts, there were the most contributions in July 11th, and 12th of 2016.
 
 And I can see that the overall contribution counts are increased from March, 2015 to March, 2016. And then it decreased and increased 2 times peaking at July, 2016 and October, 2016. It is overall trend and I can see from the line graph for each date that there are really lots of and huge fluctuations.
 
 In this time, I'm going to show the counts of contributions for each election type in Texas. I'll use bar plot again.
 
```{r echo=FALSE, Univariate_election_type_counts}

election_types_counts <- as.data.frame(
  sort(table(Data$election_tp, dnn = 'type'),
       decreasing = T), 
  responseName = 'count')

election_types_counts

ggplot(aes(x = type, y = count),
       data = election_types_counts) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 Most of contributions are for P2016 and G2016 and the contributions for P2016 are more than 2 times of the contributions for G2016. US Presidential elections are divided into 2 stages, primary and general. Therefore I think that it is right that the most of  financial contributions are for presidential eletion in 2016. 
 
 But there are some contributions whose election types, to my thinking, aren't related with it. I'm going to investigate deeply about them in the following.

```{r echo=FALSE, Consider_election_types_other_than_P2016_and_G2016}

# I'm going to print head and tail of the O2016 data because there are 68 rows.
print('Head and tail parts of datas whose election type is O2016')
o2016 = subset(Data, election_tp == 'O2016')
head(o2016)
tail(o2016)

print('Are all O2016 contributions for Jill Stein?')
all(o2016$cand_nm == 'Stein, Jill')

print('Since When and till when the contributions are received?')
range(o2016$contb_receipt_dt)

print('Datas whose election type is P2012')
subset(Data, election_tp == 'P2012')

# I'm going to print head and tail of the data whose election type is '' because there are more 1500 rows.
print("Head and tail parts of datas whose election type is ''")
election_type_vacant <- subset(Data, election_tp == '')
head(election_type_vacant)
tail(election_type_vacant)

print('For whom are the contributions?')
unique(election_type_vacant$cand_nm)

print('Since when and till when the nominees received them?')
# To answer the question, I needed to group datas by each nominees and summarise the date for each group of datas. Therefore I used functions in dplyr package.
election_type_vacant %>%
  filter(if_nominee) %>%
  group_by(cand_nm) %>%
  summarise(start_date = min(contb_receipt_dt),
            end_date = max(contb_receipt_dt)) %>%
  arrange(start_date)

# I chose line graph to show trend as time goes on. And I aggregated the daily data to monthly to show just overall trend.
ggplot(aes(x = as.Date(format(contb_receipt_dt, '%Y-%m-01'), 
                       format = '%Y-%m-%d'),
           color = cand_nm), 
       data = subset(election_type_vacant, 
                     if_nominee == T)) + 
  geom_line(stat = 'count') + 
  scale_x_date(date_breaks = '1 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

print("Since when and till when the candidates who aren't nominees received them?")
range(subset(election_type_vacant, if_nominee == F)$contb_receipt_dt)

ggplot(aes(x = contb_receipt_dt), 
       data = subset(election_type_vacant, 
                     if_nominee == F)) + 
  geom_line(stat = 'count') + 
  scale_x_date(date_breaks = '1 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 First, when I see the head and tail parts about datas whose type is O2016, it looked like they are all for Jill Stein. Thus, I checked whether the contributions are all for her and it was.
 Jill Stein was Green party nominee that I want to know since when and till when the contributions are given. And I found that they are from 2016-11-23 to 2016-11-28. It is after the election. And compared to the all election times it is really short.
 I searched about her and I found that it is related with [presidential election recount fundraising](https://en.wikipedia.org/wiki/Jill_Stein#2016). This is why they were classified as O2016, 'other' type election in 2016. It is not related with primary or general election. Therefore I think that it is better to exclude O2016 when exploring the data.
 
 
 Second, I got the datas whose type is P2012. I really wondered why the contributions related with 2012 election are in here. 
 There are only 2 contributions and I searched about ['Gunn, George'](https://www.fec.gov/data/receipts/individual-contributions/?two_year_transaction_period=2016&contributor_name=Gunn%2C+george&min_date=01%2F01%2F2015&max_date=12%2F31%2F2016&contributor_employer=HSI) and ['Wylie, Wayne'](https://www.fec.gov/data/receipts/individual-contributions/?two_year_transaction_period=2016&contributor_name=wylie%2C+wayne&min_date=01%2F01%2F2015&max_date=12%2F31%2F2016&contributor_employer=jpmorgan+chase) in FEC site. And I found that they did them to 'Rick Santorum for president, inc.(2012)'. Even though they contributed in 2015 and 2016, it looked like they did them for debt retirement for [Rick Santorum's 2012 US president election](https://en.wikipedia.org/wiki/Republican_Party_presidential_primaries,_2012). Therefore I think that the contributions are not for Santorum's 2016 election and exclude P2012 when exploring the data.
 
 Third, when I see the head and tail parts about datas whose type is '', it looked like they are all for several candidates. Thus, I checked who received the contributions and 11 candidates got them.
 In the 11 candidates, there were nominees and those who aren't. Therefore I thought that it is good to investigate the data dividing by if_nominee variable.
 When I got the contributions' start date and end date for each nominees, I found that Jill Stein got them even when she didn't begin her campaign. And Trump and McMullin got them when they are running campaigns for general election. I can find about the fact in the line graph, too. It made me think that it is better to assign the type of contributions for Trump and McMullin to G2016 and other the type of the contributions for others including Stein to P2016.
 I found that it can be applied to candidates who weren't nominees by drawing the line graph for them. The contributions for them almost stopped from July, 2016. July, 2016 was the month that [Republican](https://en.wikipedia.org/wiki/Republican_Party_presidential_primaries,_2016) and [Democratic](https://en.wikipedia.org/wiki/Democratic_Party_presidential_primaries,_2016) presidential primaries took place.
 
 
 But to be more confident to my thinking for assigning types, I searched for contributers whose names appear in the head and tail part of election_type_vacant in [FEC site](https://www.fec.gov/data/receipts/individual-contributions/?two_year_transaction_period=2016&min_date=01%2F01%2F2015&max_date=12%2F31%2F2016). 
 Refunded contributions didn't appear in the site. Some contributions are recorded as primary(one example in [here](https://www.fec.gov/data/receipts/individual-contributions/?two_year_transaction_period=2016&contributor_name=WAY%2C+RICHARD+A+MR.&min_date=01%2F01%2F2015&max_date=12%2F31%2F2016) 2016-08-26 data) instead of ''. And others are recorded '' as it is in Data. 
 I also found [FEC contribution brochure site](https://transition.fec.gov/pages/brochures/contrib.shtml) that there can be presumptive redesignations for 'Is not designated in writing for a particular election;' cases. 
 Therefore I decided to leave the election type '' as it is. And I'll also use the data of the type too distinguishing from P2016 and G2016. I think that it is the case of not designating for a particular election in writing the contribution form.

 In this time, I'm going to show the distribution of contributions for each parties in Texas. I'll use bar plot again.

```{r echo=FALSE, Univarite_party_counts}

parties_counts <- as.data.frame(sort(table(Data$cand_party, dnn = 'party'),
                                     decreasing = T),
                                responseName = 'count')

parties_counts

ggplot(aes(x = party, y = count),
       data = parties_counts) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 The most number of contributions were for Democratic party candidates. And they got about 20,000 more contributions than Republican party candidates. And rest of the parties and independent candidate got few contributions compared to the above 2 parties.
 
 It is a lot amazing that even though the candidates who were included in democratic party were just 5, the sum of contribution counts for them were more than the sum of counts for Republican party in which there were 17 candidates. I think that it means that in Democratic party there was at least one candidate who was famous in Texas and got support a lot. And the sum of contribution counts by candidate name that I explored already shows that the candidate was Hillary Clinton, Democratic party nominee.
 
 But related with contributions, the sum of amounts can be more important than the sum of counts. Therefore I'm going to explore how the sum of amounts were different by parties, candidates, election types, etc. in the bivariate sections.

 I'm going to show the distribution of contributions for nominees and those who aren't in Texas. I want to compare the 2 groups. Therefore I need to use if_nominee column which I made.

```{r echo=FALSE, Univariate_if_nominee_counts}

nominees_counts <- as.data.frame(sort(table(Data$if_nominee, 
                                            dnn = 'if_nominee'),
                                      decreasing = T),
                                 responseName = 'count')

nominees_counts

ggplot(aes(x = if_nominee, y = count),
       data = nominees_counts) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

 I wanted to compare the counts of the contributions for nominees and those who aren't. The number of contributions for nominees was about 20,000 more than the number of contributions for the others. But compared to the size of the numbers, the difference wasn't much big. I think that it means that there was at least one candidate who was likely to be a nominee and got lots of support. And the sum of contribution counts by candidate name that I explored already show that the candidates were Cruz, US Senator from Texas, and Sanders, US Senator from Vermont.

> **Tip**: Make sure that you leave a blank line between the start / end of
each code block and the end / start of your Markdown text so that it is
formatted nicely in the knitted text. Note as well that text on consecutive
lines is treated as a single space. Make sure you have a blank line between
your paragraphs so that they too are formatted for easy readability.


# Univariate Analysis

> **Tip**: Now that you've completed your univariate explorations, it's time to
reflect on and summarize what you've found. Use the questions below to help you
gather your observations and add your own if you have other thoughts!

### What is the structure of your dataset?

 There are 548396 contributions in the dataset with 20 features after merging. In these 20 features, 14 got factor type, 3 got string type and the rest 3 splited into Date, num, and logical types.
 
 Other observations by summary: 
 1. There were 25 unique candidates.
 2. Hillary Clinton got the most number of contributions.
 3. The mean of contribution amounts was \$138. And the median was \$38.
 4. There some amounts which are negatives.
 5. IQR range of the contribution dates were from 2016-02-06 to 2016-08-12.
 6. The counts of contributions for Democratic party were bigger than the counts of contributions for Republican party.

### What is/are the main feature(s) of interest in your dataset?
 
 The main feature is contb_receipt_amt, the contribution amount. And I want to know how contribution counts, sums, quantiles, and averages became different by other variables.
 
### What other features in the dataset do you think will help support your investigation into your feature(s) of interest?

 I think that cand_nm, cand_party, if_nominee, election_tp, contbr_city and contb_receipt_dt columns can help me to understand the political characteristics in Texas related with 2016 US presidential election. And I expect that receipt_desc column can sometimes give me information about the cause of some situations.

### Did you create any new variables from existing variables in the dataset?

 I created the variable 'if_nominee' from cand_nm. If cand_nm is one of 'Clinton, Hillary Rodham', 'Johnson, Gary', 'McMullin, Evan', 'Stein, Jill' and 'Trump, Donald J.', the value is TRUE. And if cand_nm is not in above 5 names, the value is FALSE.
 
### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?

 I drew the histogram of the contb_receipt_amt to IQR range and got the top 6 most common contributin amounts as a table. And I found that the most common  amount was \$25. It is not the number of tens that I thought that it was unusual. And when I drew the bar plot of contribution counts by parties, I thought that it was also unusual that a party in which had 5 candidates got more contributions by count than a party in which had 17 candidates.

 I changed the type of contb_receipt_dt column from character to Date. I did it to express the character typed values as time series. And then the variable can be used to express the trends of other variables and their values.

# Bivariate Plots Section

 Before I start drawing bivariate plots, using what I learned from univariate analysis, I'm going to make a new dataframe by subsetting Data to get only concise and essential parts.
 I'm going to select contb_receipt_amt, cand_nm, cand_party, if_nominee, election_tp, contbr_city, contb_receipt_dt and receipt_desc columns. And I'm going to exclude election type P2012 and O2016.
 
```{r echo=FALSE, Make_new_concise_dataframe}

chosenColumns = c('contb_receipt_amt', 
                  'cand_nm', 
                  'cand_party', 
                  'if_nominee', 
                  'election_tp',
                  'contbr_city', 
                  'contb_receipt_dt', 
                  'receipt_desc')

new_Data <- Data[, chosenColumns]

new_Data <- subset(new_Data, !election_tp %in% c('P2012', 'O2016'))

str(new_Data)

```

 There are 548326 contribution datas and 8 features in new dataframe.

> **Tip**: Based on what you saw in the univariate plots, what relationships
between variables might be interesting to look at in this section? Don't limit
yourself to relationships between a main output feature and one of the
supporting variables. Try to look at relationships between supporting variables
as well.

 I now start to draw bivariate plots. I want to investigate about how the contribution amounts are differed by different values in other variables first.
 
 In this time, to be more specific, I want to know how the contribution amounts changed as time goes on. Therefore I'm going to use contb_receipt_amt and contb_receipt_dt columns. And I'll draw line graphs to show the trend and scatter plot to see how the distribution of contribution amounts are changed. 

```{r echo=FALSE, Bivariate_for_amount_and_date}

ggplot(aes(x = contb_receipt_dt, y = contb_receipt_amt),
       data = new_Data) +
  geom_line(stat = 'summary', fun.y = sum) +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I designated aes(color = 'method_name') in each geom_line to make legend. 'method_name's become the name of line in legend. And I used scale_color_brewer to assign each line colors automatically. I specified size in override.aes argument to make legend lines look thicker.
# And I aggregated daily data to monthly to see the overall trend of the statistical results without severe fluctuations.
ggplot(aes(x = as.Date(format(contb_receipt_dt, '%Y-%m-01'), 
                       format = '%Y-%m-%d'), 
           y = contb_receipt_amt),
       data = new_Data) +
  geom_line(stat = 'summary', fun.y = mean,
            aes(color = 'mean')) +
  geom_line(stat = 'summary', fun.y = median,
            aes(color = 'median')) +
  geom_line(stat = 'summary', fun.y = quantile, fun.args = list(probs = 0.05),
            aes(color = '0.05quantile')) +
  geom_line(stat = 'summary', fun.y = quantile, fun.args = list(probs = 0.95),
            aes(color = '0.95quantile')) +
  scale_x_date(date_breaks = '3 month') +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Methods',
                                          override.aes = list(size = 2))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

ggplot(aes(x = contb_receipt_dt, y = contb_receipt_amt),
       data = new_Data) +
  geom_jitter(alpha = 0.05) +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I used abs function to make all amounts to positive values. And I plused 1 to make them above 0 when I transformed the scale to log. I think that adding $1 won't affect much to the values especially for amounts whose original absolute values are more than $30.
ggplot(aes(x = contb_receipt_dt, y = abs(contb_receipt_amt) + 1),
       data = new_Data) +
  geom_jitter(alpha = 0.05) +
  scale_x_date(date_breaks = '3 month') +
  scale_y_log10(breaks = c(30, 100, 300, 1000, 3000, 10000)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 And I'll draw 3 plots. First one is line graph to show the trend of sum of the contribution amounts. Second one is line graph to show the trend of mean, median, 0.05 quantile, and 0.95 quantile amounts. The other is scatter plot to see how the distribution of contribution amounts are changed.

 In this time, I want to know how the contribution amounts are differed by nominees group and other candidates group. Therefore I'm going to use contb_receipt_amt and if_nominee columns. And I'll use boxplot and barplot to show the differences. Boxplot is for seeing the distribution of amounts for each group. And barplot is for comparing the sum amounts for each group.

```{r echo=FALSE, Bivariate_for_amount_and_nominees}

ggplot(aes(x = if_nominee, y = contb_receipt_amt),
       data = new_Data) +
  geom_boxplot(alpha = 0.2) +
  scale_x_discrete()

subset_amounts_within_middle_90_percent <- subset(
  new_Data,
  contb_receipt_amt > quantile(contb_receipt_amt, 0.05) &
    contb_receipt_amt < quantile(contb_receipt_amt, 0.95)
  )

# I designated aes(shape = 'mean') in geom_point to show the means in each group of boxplots and show what the symbols mean using legend. To designate shape I used scale_shape_manual.
ggplot(aes(x = if_nominee, y = contb_receipt_amt),
       data = subset_amounts_within_middle_90_percent) +
  geom_boxplot(alpha = 0.2) +
  geom_point(stat = 'summary', fun.y = mean, size = 2, aes(shape = 'mean')) +
  scale_shape_manual('', values=c('mean' = 8)) +
  scale_x_discrete()

ggplot(aes(x = if_nominee, y = contb_receipt_amt, group = 1),
       data = new_Data) +
  geom_bar(stat = 'summary', fun.y = sum) +
  scale_x_discrete()

```

 In this time, I want to know how the contribution amounts are differed by parties. Therefore I'm going to use contb_receipt_amt and cand_party columns. And I'll use boxplot and barplot to show the differences as I did for if_nominee.

```{r echo=FALSE, Bivariate_for_amount_and_party}

ggplot(aes(x = cand_party, y = contb_receipt_amt),
       data = new_Data) +
  geom_boxplot(alpha = 0.1) +
  scale_x_discrete()

# I used again aes(shape = 'mean') and scale_shape_manual to show mean of each group.
ggplot(aes(x = cand_party, y = contb_receipt_amt),
       data = subset_amounts_within_middle_90_percent) +
  geom_boxplot(alpha = 0.2) +
  geom_point(stat = 'summary', fun.y = mean, size = 2, aes(shape = 'mean')) +
  scale_shape_manual('', values = c('mean' = 8)) +
  scale_x_discrete()

ggplot(aes(x = cand_party, y = contb_receipt_amt),
       data = new_Data) +
  geom_bar(stat = 'summary', fun.y = sum) +
  scale_x_discrete()

```

 In this time, I want to know how the contribution amounts are differed by candidates. Therefore I'm going to use contb_receipt_amt and cand_nm columns. And I'll use boxplot and barplot to show the differences as I did for cand_party.

```{r echo=FALSE, Bivariate_for_amount_and_candidates}

ggplot(aes(x = cand_nm, y = contb_receipt_amt),
       data = new_Data) +
  geom_boxplot(alpha = 0.2) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I used again aes(shape = 'mean') and scale_shape_manual to show mean of each group.
ggplot(aes(x = cand_nm, y = contb_receipt_amt),
       data = subset_amounts_within_middle_90_percent) +
  geom_boxplot(alpha = 0.2) +
  geom_point(stat = 'summary', fun.y = mean, size = 2, aes(shape = 'mean')) +
  scale_shape_manual('', values = c('mean' = 8)) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

ggplot(aes(x = cand_nm, y = contb_receipt_amt),
       data = new_Data) +
  geom_bar(stat = 'summary', fun.y = sum) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 In this time, I want to know how the contribution amounts are differed by election types. Therefore I'm going to use contb_receipt_amt and election_tp columns. And I'll use boxplot and barplot to show the differences as I did for cand_nm.

```{r echo=FALSE, Bivariate_for_amount_and_election_type}

ggplot(aes(x = election_tp, y = contb_receipt_amt),
       data = new_Data) +
  geom_boxplot(alpha = 0.2) +
  scale_x_discrete()

# I used again aes(shape = 'mean') and scale_shape_manual to show mean of each group.
ggplot(aes(x = election_tp, y = contb_receipt_amt),
       data = subset_amounts_within_middle_90_percent) +
  geom_boxplot(alpha = 0.2) +
  geom_point(stat = 'summary', fun.y = mean, size = 2, aes(shape = 'mean')) +
  scale_shape_manual('', values = c('mean' = 8)) +
  scale_x_discrete()

ggplot(aes(x = election_tp, y = contb_receipt_amt),
       data = new_Data) +
  geom_bar(stat = 'summary', fun.y = sum) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 In this time, I want to know how the contribution amounts are differed by cities. Therefore I'm going to use contb_receipt_amt and contbr_city columns. But I found in the univariate analysis that there are 2252 different city names in the Data. Therefore I'm going to show only the result of the top 10 cities by contribution counts. 
 
 I drew 4 plots. First one is boxplot to show the distribution of amounts in each city. Second one is also boxplot but only within middle 90% of amounts. Third one is line graph to show the 0.05 quantile, median, mean and 0.95 quantile amounts by each city. Fourth one is barplot to compare the sum of amounts of each city.

```{r echo=FALSE, Bivariate_for_amount_and_city}

sum_amounts_by_city <- new_Data %>%
  group_by(contbr_city) %>%
  summarise(sum_amount = sum(contb_receipt_amt),
            mean_amount = mean(contb_receipt_amt),
            median_amount = median(contb_receipt_amt),
            n = n()) %>%
  arrange(desc(n)) %>%
  head(10)

top10_sum_amounts_city <- subset(new_Data,
                                 contbr_city %in% 
                                   sum_amounts_by_city$contbr_city)

ggplot(aes(x = contbr_city, y = contb_receipt_amt),
       data = top10_sum_amounts_city) +
  geom_boxplot(alpha = 0.1) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# I used again aes(shape = 'mean') and scale_shape_manual to show mean of each group.
ggplot(aes(x = contbr_city, y = contb_receipt_amt),
       data = subset(top10_sum_amounts_city,
                     contb_receipt_amt > quantile(contb_receipt_amt, 0.05) &
                       contb_receipt_amt < quantile(contb_receipt_amt, 0.95)))+
  geom_boxplot(alpha = 0.2) +
  geom_point(stat = 'summary', fun.y = mean, size = 2, aes(shape = 'mean')) +
  scale_shape_manual('', values = c('mean' = 8)) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# To show the legend, I used again aes(color = 'method_name') in geom_line and scale_color_brewer.
ggplot(aes(x = contbr_city, y = contb_receipt_amt, group = 1),
       data = top10_sum_amounts_city) +
  geom_line(stat = 'summary', fun.y = quantile, fun.args = list(probs = 0.95),
            aes(color = '0.95quantile')) +
  geom_line(stat = 'summary', fun.y = mean,
            aes(color = 'mean')) +
  geom_line(stat = 'summary', fun.y = median,
            aes(color = 'median')) +
  geom_line(stat = 'summary', fun.y = quantile, fun.args = list(probs = 0.05),
            aes(color = '0.05quantile')) +
  scale_x_discrete() +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Methods',
                                          override.aes = list(size = 2))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

ggplot(aes(x = contbr_city, y = contb_receipt_amt, group = 1),
       data = top10_sum_amounts_city) +
  geom_bar(stat = 'summary', fun.y = sum) +
  scale_x_discrete() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 Contribution amounts are main feature that I was interested in. And I drew lots of bivariate graphs related with them.
 
 --------------------------------------------
 
 In this time, I'm going to draw bivariate graphs taking support features. And I think that contribution date is one of the important support feature that I'm going to draw graphs related with it in the following.
 
 I want to know how the daily contribution counts changed as time goes on. Especially, I want to compare between the candidates who became nominees and those who couldn't. Therefore I'm going to use contb_receipt_dt and if_nominee columns. And I'll use line graph to show the trend of contribution counts.
 
```{r echo=FALSE, Bivariate_cand_nm_and_party}

ggplot(aes(x = cand_nm, fill = cand_party),
       data = new_Data) +
  geom_bar() +
  scale_fill_brewer(type = 'qual', palette = 3) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        axis.text.y = element_blank())

```

```{r echo=FALSE, Get_main_candidates_by_contribution_counts}

main_cands_counts <- new_Data %>%
  group_by(cand_nm) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  head(7)

```


```{r echo=FALSE, Bivariate_cand_nm_and_city}

# I used sum_amounts_by_city which I already made to make top10_sum_amounts_city. In its contbr_city column, there are top 10 city names by contribution counts.
# I also used main_cands_counts to show only the result of 7 main candidates.
ggplot(aes(x = contbr_city, color = cand_nm, group = cand_nm),
       data = subset(new_Data, 
                     contbr_city %in% sum_amounts_by_city$contbr_city &
                       cand_nm %in% main_cands_counts$cand_nm)) +
  geom_line(stat = 'count') +
  scale_color_brewer(type = 'qual', 
                     palette = 2,
                     guide = guide_legend(title = 'Candidates',
                                          override.aes = list(size = 2))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

```{r echo=FALSE, Bivariate_party_and_city}

ggplot(aes(x = contbr_city, color = cand_party, group = cand_party),
       data = subset(new_Data, 
                     contbr_city %in% sum_amounts_by_city$contbr_city)) +
  geom_line(stat = 'count') +
  scale_color_brewer(type = 'qual',
                     palette = 2,
                     guide = guide_legend(title = 'Methods',
                                          override.aes = list(size = 2))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

-----------------------------------------------

 In this time, I'm going to draw bivariate graphs taking support features. And I think that contribution date is one of the important support feature that I'm going to draw graphs related with it in the following.
 
 I want to know how the daily contribution counts changed as time goes on. Especially, I want to compare between the candidates who became nominees and those who couldn't. Therefore I'm going to use contb_receipt_dt and if_nominee columns. And I'll use line graph to show the trend of contribution counts.
 
```{r echo=FALSE, Bivariate_for_date_and_nominees}

ggplot(aes(x = contb_receipt_dt, color = if_nominee),
       data = new_Data) +
  geom_line(stat = 'count') +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 In this time, I want to know how the contribution counts changed as time goes on. And I especially want to compare between the parties. Therefore I'm going to use contb_receipt_dt and cand_party columns. And I'll use line graph this time too to show the trend of contribution counts.

```{r echo=FALSE, Bivariate_for_date_and_party}

ggplot(aes(x = contb_receipt_dt, color = cand_party),
       data = new_Data) +
  geom_line(stat = 'count') +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 In this time, I want to know how the contribution counts changed as time goes on. And I especially want to compare between Trump and Clinton. Therefore I'm going to use contb_receipt_dt and cand_nm columns. And I'll use line graph again.

```{r echo=FALSE, Bivariate_for_date_and_main_nominees}

date_vs_main_nominees <- 
  ggplot(aes(x = contb_receipt_dt, color = cand_nm),
             data = subset(new_Data,
                           cand_nm %in% c('Trump, Donald J.', 
                                          'Clinton, Hillary Rodham'))) +
         geom_line(stat = 'count') +
         theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

date_vs_main_nominees + scale_x_date(date_breaks = '3 month')

date_vs_main_nominees + scale_x_date(limits = c(as.Date('2016-06-01'),
                                                as.Date('2016-11-30')),
                                     date_breaks = '1 month')

```

```{r echo=FALSE, Bivariate_for_date_and_main_republican_candidates}

ggplot(aes(x = contb_receipt_dt, color = cand_nm),
           data = subset(new_Data,
                         cand_nm %in% main_cands_counts$cand_nm &
                           cand_party == 'Republican')) +
  geom_line(stat = 'count') +
  scale_color_brewer(type = 'qual',
                     palette = 2,
                     guide = guide_legend(title = 'Methods',
                                          override.aes = list(size = 2))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

```{r echo=FALSE, Bivariate_for_date_and_main_democratic_candidates}

ggplot(aes(x = contb_receipt_dt, color = cand_nm),
           data = subset(new_Data,
                         cand_nm %in% main_cands_counts$cand_nm &
                           cand_party == 'Democratic')) +
  geom_line(stat = 'count') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

 In this time, I want to know how the contribution counts changed as time goes on. And I especially want to compare by election types. Therefore I'm going to use contb_receipt_dt and election_tp columns. And I'll again use line graph.

```{r echo=FALSE, Bivariate_date_and_election_type}

ggplot(aes(x = contb_receipt_dt, color = election_tp),
       data = new_Data) +
  geom_line(stat = 'count') +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```


# Bivariate Analysis

> **Tip**: As before, summarize what you found in your bivariate explorations
here. Use the questions below to guide your discussion.

### Talk about some of the relationships you observed in this part of the \
investigation. How did the feature(s) of interest vary with other features in \
the dataset?

### Did you observe any interesting relationships between the other features \
(not the main feature(s) of interest)?

### What was the strongest relationship you found?


# Multivariate Plots Section

> **Tip**: Now it's time to put everything together. Based on what you found in
the bivariate plots section, create a few multivariate plots to investigate
more complex interactions between variables. Make sure that the plots that you
create here are justified by the plots you explored in the previous section. If
you plan on creating any mathematical models, this is the section where you
will do that.

```{r echo=FALSE, Multivariate_Plots}

print('How contribution receipt dates for Trump and McMullin are different for P2016 and G2016 each?')

ggplot(aes(x = contb_receipt_dt, color = election_tp),
       data = subset(Data, 
                     cand_nm %in% c('Trump, Donald J.', 'McMullin, Evan') & election_tp %in% c('P2016', 'G2016'))) +
  facet_wrap(~cand_nm, scales = 'free_y', nrow = 2, dir = 'v') +
  geom_line(stat = 'count')

print("How contribution receipt dates for those who aren't nominees are different for P2016 and G2016 each?")

ggplot(aes(x = contb_receipt_dt, color = election_tp),
       data = subset(Data, 
                     !if_nominee & election_tp %in% c('P2016', 'G2016'))) +
  geom_line(stat = 'count') +
  scale_x_date(date_breaks = '3 month') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the \
investigation. Were there features that strengthened each other in terms of \
looking at your feature(s) of interest?

### Were there any interesting or surprising interactions between features?

### OPTIONAL: Did you create any models with your dataset? Discuss the \
strengths and limitations of your model.

------

# Final Plots and Summary

> **Tip**: You've done a lot of exploration and have built up an understanding
of the structure of and relationships between the variables in your dataset.
Here, you will select three plots from all of your previous exploration to
present here as a summary of some of your most interesting findings. Make sure
that you have refined your selected plots for good titling, axis labels (with
units), and good aesthetic choices (e.g. color, transparency). After each plot,
make sure you justify why you chose each plot by describing what it shows.

### Plot One
```{r echo=FALSE, Plot_One}

```

### Description One


### Plot Two
```{r echo=FALSE, Plot_Two}

```

### Description Two


### Plot Three
```{r echo=FALSE, Plot_Three}

```

### Description Three

------

# Reflection

> **Tip**: Here's the final step! Reflect on the exploration you performed and
the insights you found. What were some of the struggles that you went through?
What went well? What was surprising? Make sure you include an insight into
future work that could be done with the dataset.

> **Tip**: Don't forget to remove this, and the other **Tip** sections before
saving your final work and knitting the final report!